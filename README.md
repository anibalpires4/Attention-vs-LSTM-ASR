# Deep Learning: Architectures and Optimization

This repository contains implementations of deep learning models and techniques, developed as part of coursework at IST ULisboa. The focus is on exploring and comparing modern deep learning architectures and optimization techniques.

## Contents
This repository includes the implementation of:
1. **Optimizing Transformer Self-Attention**:
   - Analysis and reduction of computational complexity in transformers.
2. **Convolutional Neural Networks for Image Classification**:
   - Comparison of CNN architectures with and without max-pooling layers.
   - Training and validation using multiple learning rates.
3. **Encoder-Decoder Architectures for Automatic Speech Recognition**:
   - Comparative analysis of LSTM and Attention-based models for sequence-to-sequence tasks.

## Technologies
- **Programming Language**: Python
- **Frameworks**: PyTorch
- **Tools**: Jupyter Notebook, Google Colab

